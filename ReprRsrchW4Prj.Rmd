---
title: "Strms in USA, types  most harful for the population, Types most harful for the economy, based on  NOAA Storm data"
author: "Enrico"
date: "20 marzo 2017"
output: html_document
---

```{r setup, include=FALSE, cache=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
```

# Synopsys  
????????????????????????????????????????????????????????????????????  



## Overview  
Using the raw data available [here](http://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/) and documented [here](http://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/Storm-Data-Export-Format.docx) (no need to download, the code that is embedded in this document takes care of it)

type events are in column EVTYPE, 

Damage to population is in 2 variables: FATALITIES, INJURIES


## Results  

## Data Processing  

### Techical transformations for performance
By technical we mean that NO data model transformation is performed, only modification to storage format.
Data are relatively large and take several minutes to load. An attempt to reduce this loading time has been made, based on:   
- lazy loading: download from internet if local .bz2 file not present
- avoid reading directly compressed file, decompress .bz2 and read .csv, this under the assumption that reading uncompressed files is faster (assumption not punctually verified but based on first attempts to read directly compressed file, that had much longer times or hanged, all were manually terminated after running for an extremely long time)
- lazy decomopression: decompress .bz2 if .csv not present
- save to .rds, under the assumption, supported by previous experiences of the author, and some internet posts, that .rds files are faster [post 1](http://stackoverflow.com/questions/4756989/how-to-load-data-quickly-into-r)  [post 2](http://stackoverflow.com/questions/11559628/speed-up-rdata-load)

```{r dataTechProcessing}
destfilestem <- "data/StormData"
csvfile <- paste(destfilestem,".csv",sep="")
bz2file <- paste(csvfile,".bz2",sep="")
RDSFile <- paste(destfilestem,".rds",sep="")

# lazy download remote file
if(!file.exists(bz2file)){
  cat("downloading the file from inet")
  url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
  es <- tryCatch(download.file(url, bz2file
    ,method = "auto", quiet = FALSE)
    ,error=function(e) 1)
}

# lazy uncompress, not strictly necessary, hoping that makes things faster
if(!file.exists(csvfile)){
  library(R.utils)
  bunzip2(bz2file,csvfile,remove = FALSE, skip = TRUE)
}

# read data  destfile
if (!file.exists(RDSFile)) {
  cat("reading local file", csvfile)
  tempo <- system.time({
    data_org <- read.csv(csvfile)
    })
  cat(csvfile,"file read in",tempo[3], "writing in RDS format")
  saveRDS(data_org,RDSFile,compress = FALSE)
}

if (!exists(deparse(substitute(data_org)))) {
  data_org <- readRDS(RDSFile) 
}

```
### Check data status (NAs)
```{r dataCheck}

countNAs <- sapply(1:ncol(data_org), function(x) sum(is.na(data_org[x])))
colsWithNAs <- which(countNAs > 0)
names(data_org)[colsWithNAs]
```

## Logical data processing

```{r logicalDataProc}

```


## Exploratory Data Analysis, Remove  

```{r exploratoryDataAnalysis}
library(dplyr)

str(data_org)

data <- data_org[ , c("BGN_DATE", "EVTYPE", "FATALITIES", "INJURIES", "PROPDMG", "PROPDMGEXP", "CROPDMG", "CROPDMGEXP")]
names(data) <- tolower(names(data))

length(unique(data_org$evtype))
# remove(data_org) # free memory

data <- dplyr::mutate(data
  # index for people damage
  ,people_dmg_score = fatalities*10+injuries*4
  ,year = as.numeric(format(as.Date(data$bgn_date, format = "%m/%d/%Y"), "%Y")))



# let's remove years with too few records
obs_treshold <- 10000
years_grp <- group_by(data,year)
year_obs <- summarize(years_grp, obs_year = n())
year_ord <- order(year_obs$obs_year)
years_ok <- year_obs[year_obs$obs_year > obs_treshold, ]$year
data <-data[data$year %in% years_ok, ]
unique(data$year)


# index for people damage
evtype_grp <- group_by(data,evtype)
people_dmg_sums <- summarize(evtype_grp,people_sum = sum(people_dmg_score))
people_order <- people_dmg_sums[order(-people_dmg_sums$people_sum), ]
people_order[(people_order$people_sum > 0),]

library(ggplot2)
toPlot <- people_order[1:10,]
p <- ggplot(toPlot, aes(evtype,people_sum))
p <- p + geom_bar(stat='identity')
p <- p + theme(axis.text.x=element_text(angle=90))
p <- p + ggtitle("The 10 Storm Types That Cause More People Damage")
p <- p +xlab("Storm Type")
p <- p +ylab("People Damage Score")
p
```

Transform exponent columns from factors to chars to simplify processing
```{r factorsToChars, results='hide'}
data$propdmgexp <-  lapply(data$propdmgexp, as.character)
data$cropdmgexp <-  lapply(data$cropdmgexp, as.character)

```

Value for property and crop damage is, in both cases, split in two columns
- propdmg, propdmg<b>exp</b>  
- copdmg, cropdmg<b>exp</b>  
I build two new columns, property and crops, containing the values
```{r calculateValues, results='hide'}

multiplier <- function(x){
if (is.na(x) || nchar(x) == 0) 
    return(1)
if(is.numeric(x)) {
    return(10^x)
}
myexp <- switch(tolower(x),
    " " = 0,
    "-" = -1,
    "+" = 1,
    "0" = 0,
    "1" = 1,
    "2" = 2,
    "3" = 3,
    "4" = 4,
    "5" = 5,
    "6" = 6,
    "7" = 7,
    "8" = 8,
    "9" = 9,
    "h" = 2,
    "k" = 3,
    "m" = 6,
    "b" = 9,
    0
  )
  10^myexp
}

#library(data.table); data <- data.table(data)

j <- 0 
data$property <- sapply(1:nrow(data), function(i) {
  if (is.na(data[i,5]) || data[i,5] == 0)
    return(0)
  ret <- data[i,5]*multiplier(data[i,6])
  #cat(paste("[",i,"] ",ret, "=", data[i,5],",",data[i,6]," mult ", multiplier(data[i,6]),"\n"))
  j <<- j+1
  # if (j%%1000 == 0) cat(" ",j/1000)
  return(ret)
  })
j <- 0
data$crops <- sapply(1:nrow(data), function(i) {
  if (is.na(data[i,7]) || data[i,7] == 0)
    return(0)
  ret <- data[i,7]*multiplier(data[i,8])
  #cat(paste("[",i,"] ",ret, "=", data[i,5],",",data[i,6]," mult ", multiplier(data[i,6]),"\n"))
  j <<- j+1;  if (j%%1000 == 0) cat(" ",j/1000)
  return(ret)
  })

data$econ_dmg <- data$property + data$crops

saveRDS(data,"data_ok.rds")

```

## Storm Types and Property Damage

```{r calculateValues, results='hide'}
library(ggplot2)

# economic damage
eco_dmg_sums <- summarize(evtype_grp,eco_sum = sum(econ_dmg))
eco_order <- eco_dmg_sums[order(-eco_dmg_sums$eco_sum), ]
eco_order[(eco_order$eco_sum > 0),]
eco_order <- eco_order[1:10, ]

p <- ggplot(eco_order, aes(evtype,eco_sum))
p <- p + geom_bar(stat='identity')
p <- p + theme(axis.text.x=element_text(angle=90))
p <- p + ggtitle("The 10 Storm Types That Cause More Economic Damage")
p <- p +xlab("Storm Type")
p <- p +ylab("Economic Damage")
p
```


## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
